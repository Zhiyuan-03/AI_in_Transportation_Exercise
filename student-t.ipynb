{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZwrLaEdYTyJe1rI5SIWG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhiyuan-03/AI_in_Transportation_Exercise/blob/main/student-t.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load data\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Step 1: Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Load the uploaded CSV file\n",
        "# Replace 'cf_pair25_v1.csv' with the exact filename you uploaded\n",
        "data = pd.read_csv('cf_pair25_v1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "A-pNDPw9qW4R",
        "outputId": "98a13668-1552-4a6d-a66e-f30b8f7847aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-acda4f11-06b8-44ee-a991-6b4ceab1ada3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-acda4f11-06b8-44ee-a991-6b4ceab1ada3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cf_pair25_v1.csv to cf_pair25_v1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu_dVIuYqTT_",
        "outputId": "f1940e83-1347-4f16-86d4-9cef58219b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation vehicle IDs: [12638, 10, 9683, 3054, 5167]\n",
            "Fold starting 0: params_1=[0.75593846 1.38109498], params_2=[0.73842678 1.32395696], params_3=[0.75590044 1.38093823], params_4=[0.85660951 1.79340337 0.27126915 8.35425239]\n",
            "  test GOF (MSE) -> LS: 0.2197, GOF-min: 0.2191, Gauss-LL: 0.2197, Student-t: 0.2215\n",
            "Fold starting 4: params_1=[0.71862851 1.81564563], params_2=[0.70583855 1.84258958], params_3=[0.71865855 1.81582272], params_4=[0.86515607 2.32532842 0.27841002 5.73665023]\n",
            "  test GOF (MSE) -> LS: 0.0833, GOF-min: 0.0842, Gauss-LL: 0.0833, Student-t: 0.0838\n",
            "Fold starting 8: params_1=[0.66436438 1.39249402], params_2=[0.64804878 1.38280044], params_3=[0.66433324 1.39233505], params_4=[0.84497041 1.94062609 0.27366904 5.16285435]\n",
            "  test GOF (MSE) -> LS: 0.0761, GOF-min: 0.0762, Gauss-LL: 0.0761, Student-t: 0.0756\n",
            "Fold starting 12: params_1=[0.67615806 1.45376773], params_2=[0.66204301 1.44916326], params_3=[0.67610148 1.45345953], params_4=[0.83148178 1.91480584 0.26648982 4.98553144]\n",
            "  test GOF (MSE) -> LS: 0.0932, GOF-min: 0.0932, Gauss-LL: 0.0932, Student-t: 0.0930\n",
            "Fold starting 16: params_1=[0.70196217 1.69719548], params_2=[0.68625036 1.67143189], params_3=[0.70197061 1.69723535], params_4=[0.78991071 1.8161249  0.28031646 6.92695832]\n",
            "  test GOF (MSE) -> LS: 0.1293, GOF-min: 0.1296, Gauss-LL: 0.1293, Student-t: 0.1286\n",
            "\n",
            "least_squares (a,b) summary over folds:\n",
            "  param[0]: mean=0.7034, std=0.0324\n",
            "  param[1]: mean=1.5480, std=0.1760\n",
            "\n",
            "minimize_gof (a,b) summary over folds:\n",
            "  param[0]: mean=0.6881, std=0.0320\n",
            "  param[1]: mean=1.5340, std=0.1941\n",
            "\n",
            "minimize_ll (a,b) summary over folds:\n",
            "  param[0]: mean=0.7034, std=0.0324\n",
            "  param[1]: mean=1.5480, std=0.1761\n",
            "\n",
            "minimize_student_t (a,b,sigma,nu) summary over folds:\n",
            "  param[0]: mean=0.8376, std=0.0264\n",
            "  param[1]: mean=1.9581, std=0.1920\n",
            "  param[2]: mean=0.2740, std=0.0050\n",
            "  param[3]: mean=6.2332, std=1.2593\n",
            "\n",
            "Mean test GOFs (MSE) across folds:\n",
            "  least_squares: 0.120321 (n=5)\n",
            "  minimize_gof: 0.120475 (n=5)\n",
            "  minimize_ll: 0.120321 (n=5)\n",
            "  minimize_student_t: 0.120529 (n=5)\n",
            "\n",
            "Fitting final Student-t model on the full dataset...\n",
            "Final student-t params: a=0.8357, b=1.9810, sigma=0.2731, nu=5.8311\n",
            "Final log-likelihood: -5158.0541 (negll=5158.0541)\n",
            "AIC = 10324.108, BIC = 10355.134, n_obs = 17263\n",
            "\n",
            "Residual summary (Student-t fit):\n",
            "  n_res = 17263\n",
            "  residual mean = -0.032453, std = 0.336451\n",
            "  standardized residual mean = -0.118851, std = 1.232181\n",
            "Shapiro-Wilk on standardized residuals (first 5000 if >5000): W=0.9588, p=1.799e-35\n",
            "Anderson-Darling statistic: 52.36272342073789 critical: [0.576 0.656 0.787 0.918 1.092]\n",
            "Saved Q–Q plot vs Student-t to Plots/qq_student_t.png\n",
            "Saved histogram of standardized residuals to Plots/hist_std_residuals.png\n",
            "Saved residuals vs index plot to Plots/residuals_index.png\n",
            "Saved residual-by-vehicle plots for up to 6 vehicles in Plots\n",
            "\n",
            "Final evaluation on held-out evaluation vehicles:\n",
            "  MSE (GOF) = 0.108386, negative-LL (Gaussian, using sigma=1.0) = 3601.613382\n",
            "  Mean R^2 (pos, speed) = [0.99958577 0.91122766]\n",
            "Saved evaluation obs-vs-sim plots for held-out vehicles to Plots\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# 0. Imports and configuration\n",
        "# ===============================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import least_squares, minimize\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import anderson, shapiro\n",
        "from scipy.special import gammaln\n",
        "import scipy.stats as stats\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "TIME_STEP = 0.1    # seconds\n",
        "SIGMA      = 1.0   # noise std for Gaussian LL (used in non-Student-t codes)\n",
        "MOP        = \"speed\"  # \"speed\" or \"position\"\n",
        "PLOT_DIR   = \"Plots\"\n",
        "os.makedirs(PLOT_DIR, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 1. IDM model\n",
        "# ===============================\n",
        "def idm_model(s, v, delta_v, params, T=1.5, v0=30, s0=1):\n",
        "    a, b = params\n",
        "    delta = 4\n",
        "    # s_star as in classical IDM\n",
        "    s_star = s0 + v * T + (v * delta_v) / (2 * np.sqrt(a * b))\n",
        "    acceleration = a * (1 - (v / v0) ** delta - (s_star / s) ** 2)\n",
        "    return acceleration\n",
        "\n",
        "# ===============================\n",
        "# 2. Calibration function\n",
        "# ===============================\n",
        "def calibration(params, df, mop=\"position\", time_step=TIME_STEP, sigma=SIGMA):\n",
        "    \"\"\"\n",
        "    Simulate each vehicle's trajectory using `params` and return:\n",
        "    residuals, mean_gof, negative_log_likelihood, mean_r2 (pos, speed), trajectories, speed_curves\n",
        "    Note: negative_log_likelihood uses Gaussian LL with `sigma` when mop is position/speed.\n",
        "    \"\"\"\n",
        "    residuals = []\n",
        "    total_gof = 0.0\n",
        "    total_ll  = 0.0\n",
        "    r2_list   = []\n",
        "    vehicle_count = 0\n",
        "    trajectories = {}\n",
        "    speed_curves = {}\n",
        "\n",
        "    grouped = df.groupby('Vehicle_ID_f')\n",
        "    for vehicle_id, data in grouped:\n",
        "        v0 = data[\"v_f\"].iloc[0]\n",
        "        x0 = data[\"x_f\"].iloc[0]\n",
        "        v_lead = data[\"v_l\"].values\n",
        "        x_lead = data[\"x_l\"].values\n",
        "        obs_v = data[\"v_f\"].values\n",
        "        obs_x = data[\"x_f\"].values\n",
        "        sim_v = [v0]\n",
        "        sim_x = [x0]\n",
        "        time     = data[\"Frame_ID_f\"].values\n",
        "        length_l = data['length_l'].values\n",
        "        length_f = data['length_f'].values\n",
        "\n",
        "        for i in range(1, len(data)):\n",
        "            vL = v_lead[i-1]; xL = x_lead[i-1]\n",
        "            v  = sim_v[i-1]; x  = sim_x[i-1]\n",
        "            s = xL - x - (length_l[i-1] + length_f[i-1]) / 2.0\n",
        "            delta_v = v - vL\n",
        "            acc = idm_model(s, v, delta_v, params)\n",
        "            v_next = max(v + acc * time_step, 0.0)\n",
        "            x_next = x + (v_next + v) / 2.0 * time_step\n",
        "            sim_v.append(v_next); sim_x.append(x_next)\n",
        "\n",
        "        if mop == \"position\":\n",
        "            res = obs_x - np.array(sim_x)\n",
        "            gof = np.mean(res**2)\n",
        "            ll  = -0.5 * np.sum((res / sigma) ** 2 + np.log(2 * np.pi * sigma**2))\n",
        "        elif mop == \"speed\":\n",
        "            res = obs_v - np.array(sim_v)\n",
        "            gof = np.mean(res**2)\n",
        "            ll  = -0.5 * np.sum((res / sigma) ** 2 + np.log(2 * np.pi * sigma**2))\n",
        "        else:\n",
        "            raise ValueError(\"mop must be 'position' or 'speed'.\")\n",
        "\n",
        "        residuals.extend(res)\n",
        "        total_gof += gof; total_ll += ll; vehicle_count += 1\n",
        "        # compute R^2 (catch degenerate cases)\n",
        "        try:\n",
        "            r2_pos   = r2_score(obs_x, sim_x)\n",
        "        except Exception:\n",
        "            r2_pos = np.nan\n",
        "        try:\n",
        "            r2_speed = r2_score(obs_v, sim_v)\n",
        "        except Exception:\n",
        "            r2_speed = np.nan\n",
        "        r2_list.append([r2_pos, r2_speed])\n",
        "\n",
        "        trajectories[vehicle_id] = {\"obs_x\": obs_x, \"sim_x\": np.array(sim_x), \"x_lead\": x_lead, \"time\": time}\n",
        "        speed_curves[vehicle_id] = {\"obs_v\": obs_v, \"sim_v\": np.array(sim_v), \"v_lead\": v_lead, \"time\": time}\n",
        "\n",
        "    mean_r2 = np.nanmean(np.array(r2_list), axis=0)\n",
        "    return residuals, total_gof / max(vehicle_count, 1), -total_ll, mean_r2, trajectories, speed_curves\n",
        "\n",
        "def calibration_gof(params, data, mop, number):\n",
        "    \"\"\"\n",
        "    Helper wrapper used during optimization.\n",
        "    If number == 0 -> returns full residual vector (for least_squares)\n",
        "    If number == 1 -> returns GOF scalar (used with minimize to minimize GOF)\n",
        "    If number == 2 -> returns negative log-likelihood scalar (used with minimize)\n",
        "    \"\"\"\n",
        "    result = calibration(params, data, mop)\n",
        "    return result[number]\n",
        "\n",
        "# ===============================\n",
        "# 3. NLL functions\n",
        "# ===============================\n",
        "def simulate_v(data, params, time_step=TIME_STEP):\n",
        "    v_f = data['v_f'].iloc[0]; x_f = data['x_f'].iloc[0]\n",
        "    v_l = data['v_l'].values; x_l = data['x_l'].values\n",
        "    v_sim = [v_f]; x_sim = [x_f]\n",
        "    lengths_l = data['length_l'].values; lengths_f = data['length_f'].values\n",
        "    for i in range(1, len(data)):\n",
        "        s = x_l[i-1] - x_sim[-1] - (lengths_l[i-1] + lengths_f[i-1]) / 2.0\n",
        "        delta_v = v_sim[-1] - v_l[i-1]\n",
        "        acc = idm_model(s, v_sim[-1], delta_v, params)\n",
        "        new_v = max(v_sim[-1] + acc * time_step, 0.0)\n",
        "        new_x = x_sim[-1] + (new_v + v_sim[-1]) / 2.0 * time_step\n",
        "        v_sim.append(new_v); x_sim.append(new_x)\n",
        "    return np.array(v_sim)\n",
        "\n",
        "def log_likelihood(params, df, time_step=TIME_STEP, sigma=SIGMA):\n",
        "    \"\"\"\n",
        "    Gaussian negative log-likelihood across vehicles (returns -total_ll, suitable for minimization).\n",
        "    \"\"\"\n",
        "    total_ll = 0.0\n",
        "    for vid, data in df.groupby('Vehicle_ID_f'):\n",
        "        v_obs = data['v_f'].values\n",
        "        v_sim = simulate_v(data, params, time_step)\n",
        "        residuals = v_obs - v_sim\n",
        "        ll = -0.5 * np.sum((residuals / sigma) ** 2 + np.log(2 * np.pi * sigma**2))\n",
        "        total_ll += ll\n",
        "    return -total_ll\n",
        "\n",
        "def nll_student_t(params, df, time_step=TIME_STEP):\n",
        "    \"\"\"\n",
        "    Negative log-likelihood for Student-t errors.\n",
        "    params = [a, b, sigma, nu]\n",
        "    We return -total_log_likelihood (so minimizing this finds MLE).\n",
        "    \"\"\"\n",
        "    a, b, sigma, nu = params\n",
        "    if sigma <= 0 or nu <= 0:\n",
        "        return 1e12  # penalty for invalid parameters\n",
        "    total_ll = 0.0\n",
        "    c = gammaln((nu+1)/2) - gammaln(nu/2) - 0.5*np.log(nu*np.pi) - np.log(sigma)\n",
        "    for vid, data in df.groupby('Vehicle_ID_f'):\n",
        "        v_obs = data['v_f'].values\n",
        "        v_sim = simulate_v(data, [a, b], time_step)\n",
        "        r = v_obs - v_sim\n",
        "        # Student-t log pdf (vectorized)\n",
        "        ll = np.sum(c - ((nu+1)/2)*np.log(1 + (r**2)/(nu*sigma**2)))\n",
        "        total_ll += ll\n",
        "    return -total_ll\n",
        "\n",
        "# ===============================\n",
        "# 4. Data loading and split\n",
        "# ===============================\n",
        "data = pd.read_csv('cf_pair25_v1.csv')\n",
        "vehicle_ids = data[\"Vehicle_ID_f\"].unique()\n",
        "N = len(vehicle_ids)\n",
        "vehicle_ids_eval      = vehicle_ids[-5:]\n",
        "vehicle_ids_crossval  = vehicle_ids[:-5]\n",
        "print(\"Evaluation vehicle IDs:\", [int(x) for x in vehicle_ids_eval])\n",
        "\n",
        "# ===============================\n",
        "# 5. Cross-validation\n",
        "# ===============================\n",
        "mop = MOP\n",
        "trajectories = {}; speed_curves = {}\n",
        "all_params_1, all_params_2, all_params_3, all_params_4 = [], [], [], []\n",
        "test_gof = {'least_squares': [], 'minimize_gof': [], 'minimize_ll': [], 'minimize_student_t': []}\n",
        "\n",
        "bounds_1 = ([0.1, 0.1], [7.0, 7.0])  # for least_squares (a,b)\n",
        "bounds_2 = [(0.1, 7.0), (0.1, 7.0)]  # for minimize with (a,b)\n",
        "bounds_4 = [(0.1, 7.0), (0.1, 7.0), (1e-3, 5.0), (2.1, 200.0)]  # for (a,b,sigma,nu)\n",
        "initial_guess = [0.7, 1.5]\n",
        "\n",
        "# We'll iterate through cross-validation folds\n",
        "for start in range(0, len(vehicle_ids_crossval), 4):\n",
        "    test_ids  = vehicle_ids[start:start+4]\n",
        "    train_ids = np.setdiff1d(vehicle_ids, test_ids)\n",
        "    train_df = data[data[\"Vehicle_ID_f\"].isin(train_ids)]\n",
        "    test_df  = data[data[\"Vehicle_ID_f\"].isin(test_ids)]\n",
        "\n",
        "    # ----- result_1: least_squares on residual vector (minimize residuals directly) -----\n",
        "    try:\n",
        "        result_1 = least_squares(calibration_gof, x0=initial_guess, args=(train_df, mop, 0),\n",
        "                                 bounds=bounds_1)\n",
        "        params_1 = result_1.x\n",
        "    except Exception as e:\n",
        "        print(\"least_squares failed in fold starting at\", start, \":\", e)\n",
        "        params_1 = np.array(initial_guess)\n",
        "    all_params_1.append(params_1)\n",
        "\n",
        "    # ----- result_2: minimize GOF (mean squared error) -----\n",
        "    try:\n",
        "        result_2 = minimize(calibration_gof, x0=initial_guess, args=(train_df, mop, 1),\n",
        "                            bounds=bounds_2, method=\"L-BFGS-B\")\n",
        "        params_2 = result_2.x\n",
        "    except Exception as e:\n",
        "        print(\"minimize (gof) failed in fold starting at\", start, \":\", e)\n",
        "        params_2 = np.array(initial_guess)\n",
        "    all_params_2.append(params_2)\n",
        "\n",
        "    # ----- result_3: minimize Gaussian negative log-likelihood (using calibration) -----\n",
        "    try:\n",
        "        result_3 = minimize(calibration_gof, x0=initial_guess, args=(train_df, mop, 2),\n",
        "                            bounds=bounds_2, method=\"L-BFGS-B\")\n",
        "        params_3 = result_3.x\n",
        "    except Exception as e:\n",
        "        print(\"minimize (gaussian ll) failed in fold starting at\", start, \":\", e)\n",
        "        params_3 = np.array(initial_guess)\n",
        "    all_params_3.append(params_3)\n",
        "\n",
        "    # ----- result_4: minimize Student-t negative log-likelihood (a, b, sigma, nu) -----\n",
        "    try:\n",
        "        # initial for student-t: (a,b,sigma,nu)\n",
        "        init_student = [0.7, 1.5, 1.0, 5.0]\n",
        "        result_4 = minimize(nll_student_t, x0=init_student, args=(train_df,),\n",
        "                            bounds=bounds_4, method=\"L-BFGS-B\",\n",
        "                            options={'maxiter': 2000})\n",
        "        params_4 = result_4.x\n",
        "    except Exception as e:\n",
        "        print(\"minimize (student-t) failed in fold starting at\", start, \":\", e)\n",
        "        params_4 = np.array([0.7, 1.5, 1.0, 5.0])\n",
        "    all_params_4.append(params_4)\n",
        "\n",
        "    # ----- Evaluate each model on the test set using calibration (GOF) -----\n",
        "    # least_squares params\n",
        "    try:\n",
        "        _, gof1, negll1, r2_1, _, _ = calibration(params_1, test_df, mop=mop)\n",
        "    except Exception as e:\n",
        "        gof1 = np.nan; negll1 = np.nan; r2_1 = [np.nan, np.nan]\n",
        "    # minimize GOF params\n",
        "    try:\n",
        "        _, gof2, negll2, r2_2, _, _ = calibration(params_2, test_df, mop=mop)\n",
        "    except Exception as e:\n",
        "        gof2 = np.nan; negll2 = np.nan; r2_2 = [np.nan, np.nan]\n",
        "    # minimize Gaussian LL params\n",
        "    try:\n",
        "        _, gof3, negll3, r2_3, _, _ = calibration(params_3, test_df, mop=mop)\n",
        "    except Exception as e:\n",
        "        gof3 = np.nan; negll3 = np.nan; r2_3 = [np.nan, np.nan]\n",
        "    # student-t params (note params_4 contains sigma and nu too)\n",
        "    try:\n",
        "        _, gof4, negll4, r2_4, _, _ = calibration(params_4[:2], test_df, mop=mop)\n",
        "    except Exception as e:\n",
        "        gof4 = np.nan; negll4 = np.nan; r2_4 = [np.nan, np.nan]\n",
        "\n",
        "    test_gof['least_squares'].append(gof1)\n",
        "    test_gof['minimize_gof'].append(gof2)\n",
        "    test_gof['minimize_ll'].append(gof3)\n",
        "    test_gof['minimize_student_t'].append(gof4)\n",
        "\n",
        "    print(f\"Fold starting {start}: params_1={params_1}, params_2={params_2}, params_3={params_3}, params_4={params_4}\")\n",
        "    print(f\"  test GOF (MSE) -> LS: {gof1:.4f}, GOF-min: {gof2:.4f}, Gauss-LL: {gof3:.4f}, Student-t: {gof4:.4f}\")\n",
        "\n",
        "# ===============================\n",
        "# 6. Summaries across folds\n",
        "# ===============================\n",
        "def summarise_params(param_list, name):\n",
        "    mat = np.array(param_list)\n",
        "    print(f\"\\n{name} summary over folds:\")\n",
        "    if mat.size == 0:\n",
        "        print(\"  (no results)\")\n",
        "        return\n",
        "    for i in range(mat.shape[1]):\n",
        "        col = mat[:, i]\n",
        "        print(f\"  param[{i}]: mean={np.nanmean(col):.4f}, std={np.nanstd(col):.4f}\")\n",
        "\n",
        "summarise_params(all_params_1, \"least_squares (a,b)\")\n",
        "summarise_params(all_params_2, \"minimize_gof (a,b)\")\n",
        "summarise_params(all_params_3, \"minimize_ll (a,b)\")\n",
        "summarise_params(all_params_4, \"minimize_student_t (a,b,sigma,nu)\")\n",
        "\n",
        "print(\"\\nMean test GOFs (MSE) across folds:\")\n",
        "for k, v in test_gof.items():\n",
        "    print(f\"  {k}: {np.nanmean(v):.6f} (n={len(v)})\")\n",
        "\n",
        "# ===============================\n",
        "# 7. Final Student-t fit on full dataset & evaluation\n",
        "# ===============================\n",
        "print(\"\\nFitting final Student-t model on the full dataset...\")\n",
        "init_student = [0.7, 1.5, 1.0, 5.0]\n",
        "try:\n",
        "    final_student = minimize(nll_student_t, x0=init_student, args=(data,),\n",
        "                             bounds=bounds_4, method=\"L-BFGS-B\",\n",
        "                             options={'maxiter': 4000})\n",
        "    a_hat, b_hat, sigma_hat, nu_hat = final_student.x\n",
        "    final_negll = float(final_student.fun)\n",
        "    final_ll = -final_negll\n",
        "    print(f\"Final student-t params: a={a_hat:.4f}, b={b_hat:.4f}, sigma={sigma_hat:.4f}, nu={nu_hat:.4f}\")\n",
        "    print(f\"Final log-likelihood: {final_ll:.4f} (negll={final_negll:.4f})\")\n",
        "except Exception as e:\n",
        "    print(\"Final student-t fit failed:\", e)\n",
        "    a_hat, b_hat, sigma_hat, nu_hat = (0.7, 1.5, 1.0, 5.0)\n",
        "    final_negll = np.nan\n",
        "    final_ll = np.nan\n",
        "\n",
        "# Compute AIC / BIC\n",
        "k_params = 4\n",
        "n_obs = len(data)  # total number of rows (observations)\n",
        "if not np.isnan(final_negll):\n",
        "    AIC = 2 * k_params + 2 * final_negll\n",
        "    BIC = k_params * np.log(n_obs) + 2 * final_negll\n",
        "    print(f\"AIC = {AIC:.3f}, BIC = {BIC:.3f}, n_obs = {n_obs}\")\n",
        "else:\n",
        "    print(\"AIC/BIC cannot be computed because final_negll is NaN\")\n",
        "\n",
        "# ===============================\n",
        "# 8. Residual analysis for Student-t model (final fit)\n",
        "# ===============================\n",
        "# Collect residuals across all vehicles\n",
        "residuals_all = []\n",
        "std_residuals_all = []\n",
        "index_all = []\n",
        "vehicle_ix = []\n",
        "for vid, group in data.groupby('Vehicle_ID_f'):\n",
        "    v_obs = group['v_f'].values\n",
        "    v_sim = simulate_v(group, [a_hat, b_hat], TIME_STEP)\n",
        "    r = v_obs - v_sim\n",
        "    residuals_all.extend(r)\n",
        "    std_residuals_all.extend(r / sigma_hat)\n",
        "    # index: use order within vehicle relative to dataset-global index for plotting\n",
        "    index_all.extend(list(group.index.values))\n",
        "    vehicle_ix.extend([vid] * len(r))\n",
        "\n",
        "residuals_all = np.array(residuals_all)\n",
        "std_residuals_all = np.array(std_residuals_all)\n",
        "index_all = np.array(index_all)\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nResidual summary (Student-t fit):\")\n",
        "print(f\"  n_res = {len(residuals_all)}\")\n",
        "print(f\"  residual mean = {np.mean(residuals_all):.6f}, std = {np.std(residuals_all):.6f}\")\n",
        "print(f\"  standardized residual mean = {np.mean(std_residuals_all):.6f}, std = {np.std(std_residuals_all):.6f}\")\n",
        "\n",
        "# Normality tests on standardized residuals (note: these assume normality; for student-t one expects t tails)\n",
        "try:\n",
        "    sh_w, sh_p = shapiro(std_residuals_all if len(std_residuals_all) <= 5000 else std_residuals_all[:5000])\n",
        "    print(f\"Shapiro-Wilk on standardized residuals (first 5000 if >5000): W={sh_w:.4f}, p={sh_p:.4g}\")\n",
        "except Exception as e:\n",
        "    print(\"Shapiro test failed:\", e)\n",
        "\n",
        "try:\n",
        "    ad_res = anderson(std_residuals_all)\n",
        "    print(\"Anderson-Darling statistic:\", ad_res.statistic, \"critical:\", ad_res.critical_values)\n",
        "except Exception as e:\n",
        "    print(\"Anderson test failed:\", e)\n",
        "\n",
        "# -------------------------\n",
        "# QQ plot vs Student-t\n",
        "# -------------------------\n",
        "plt.figure(figsize=(6,6))\n",
        "# Use scipy.stats.probplot with distribution = t and sparams=(nu,)\n",
        "# probplot will produce points against theoretical quantiles of Student-t (which has mean 0)\n",
        "try:\n",
        "    # If nu_hat is not sensible, fallback\n",
        "    nu_for_qq = max(nu_hat, 2.1)\n",
        "    (osm, osr), (slope, intercept, r) = stats.probplot(std_residuals_all, dist=stats.t, sparams=(nu_for_qq,), fit=True)\n",
        "    # probplot with dist=t returns arrays suitable for scatterplot, but to draw line manually:\n",
        "    plt.scatter(osm, osr, marker='o', s=8, alpha=0.6, label='Std residuals')\n",
        "    # Draw fitted line\n",
        "    x_line = np.array([np.min(osm), np.max(osm)])\n",
        "    y_line = intercept + slope * x_line\n",
        "    plt.plot(x_line, y_line, color='k', lw=1.0, label='Fit line')\n",
        "    plt.xlabel('Theoretical quantiles (Student-t)')\n",
        "    plt.ylabel('Ordered standardized residuals')\n",
        "    plt.title(f'Q–Q plot (Student-t dist, df={nu_for_qq:.2f})')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=':', alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    qq_path = os.path.join(PLOT_DIR, 'qq_student_t.png')\n",
        "    plt.savefig(qq_path, dpi=200)\n",
        "    plt.close()\n",
        "    print(\"Saved Q–Q plot vs Student-t to\", qq_path)\n",
        "except Exception as e:\n",
        "    print(\"QQ-plot failed:\", e)\n",
        "\n",
        "# -------------------------\n",
        "# Histogram of standardized residuals\n",
        "# -------------------------\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(std_residuals_all, bins=50, density=True, alpha=0.7)\n",
        "# overlay Student-t pdf for comparison\n",
        "try:\n",
        "    xs = np.linspace(np.percentile(std_residuals_all, 0.5), np.percentile(std_residuals_all, 99.5), 300)\n",
        "    pdf_t = stats.t.pdf(xs, df=nu_hat)\n",
        "    plt.plot(xs, pdf_t, lw=2, label=f\"Student-t pdf (df={nu_hat:.2f})\")\n",
        "except Exception:\n",
        "    pass\n",
        "plt.xlabel('Standardized residuals (r / sigma_hat)')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Histogram of standardized residuals (Student-t fit)')\n",
        "plt.grid(True, linestyle=':', alpha=0.4)\n",
        "plt.legend()\n",
        "hist_path = os.path.join(PLOT_DIR, 'hist_std_residuals.png')\n",
        "plt.tight_layout()\n",
        "plt.savefig(hist_path, dpi=200)\n",
        "plt.close()\n",
        "print(\"Saved histogram of standardized residuals to\", hist_path)\n",
        "\n",
        "# -------------------------\n",
        "# Residual vs. index plot\n",
        "# -------------------------\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.scatter(index_all, residuals_all, s=8, alpha=0.6)\n",
        "plt.axhline(0, color='k', lw=1)\n",
        "plt.xlabel('Data index (global row index)')\n",
        "plt.ylabel('Residual (v_obs - v_sim)')\n",
        "plt.title('Residuals vs. Index (order in dataset)')\n",
        "plt.grid(True, linestyle=':', alpha=0.4)\n",
        "res_index_path = os.path.join(PLOT_DIR, 'residuals_index.png')\n",
        "plt.tight_layout()\n",
        "plt.savefig(res_index_path, dpi=200)\n",
        "plt.close()\n",
        "print(\"Saved residuals vs index plot to\", res_index_path)\n",
        "\n",
        "# -------------------------\n",
        "# Residuals by vehicle (optional quick check) - save one plot per first few vehicles\n",
        "# -------------------------\n",
        "unique_vehicles = np.unique(vehicle_ix)\n",
        "for v in unique_vehicles[:6]:\n",
        "    mask = np.array(vehicle_ix) == v\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.plot(np.where(mask)[0], residuals_all[mask], marker='o', linestyle='-', markersize=4)\n",
        "    plt.axhline(0, color='k', lw=1)\n",
        "    plt.xlabel('Observation index within dataset')\n",
        "    plt.ylabel('Residual')\n",
        "    plt.title(f'Residuals for Vehicle {v}')\n",
        "    plt.grid(True, linestyle=':', alpha=0.4)\n",
        "    fn = os.path.join(PLOT_DIR, f'res_vehicle_{int(v)}.png')\n",
        "    plt.tight_layout(); plt.savefig(fn, dpi=180); plt.close()\n",
        "\n",
        "print(f\"Saved residual-by-vehicle plots for up to 6 vehicles in {PLOT_DIR}\")\n",
        "\n",
        "# ===============================\n",
        "# 9. Final evaluation on held-out evaluation vehicles\n",
        "# ===============================\n",
        "eval_df = data[data[\"Vehicle_ID_f\"].isin(vehicle_ids_eval)]\n",
        "_, eval_gof, eval_negll, eval_r2, eval_trajectories, eval_speedcurves = calibration([a_hat, b_hat], eval_df, mop=mop)\n",
        "print(\"\\nFinal evaluation on held-out evaluation vehicles:\")\n",
        "print(f\"  MSE (GOF) = {eval_gof:.6f}, negative-LL (Gaussian, using sigma={SIGMA}) = {eval_negll:.6f}\")\n",
        "print(f\"  Mean R^2 (pos, speed) = {eval_r2}\")\n",
        "\n",
        "# Optionally visualize observed vs simulated for a held-out vehicle\n",
        "for vid in vehicle_ids_eval:\n",
        "    g = eval_trajectories.get(vid, None)\n",
        "    sc = eval_speedcurves.get(vid, None)\n",
        "    if g is None or sc is None:\n",
        "        continue\n",
        "    t = g['time']\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(t, g['obs_x'], label='obs_x')\n",
        "    plt.plot(t, g['sim_x'], label='sim_x')\n",
        "    plt.xlabel('Frame ID'); plt.ylabel('Position'); plt.title(f'Vehicle {int(vid)} position')\n",
        "    plt.legend(); plt.grid(True, linestyle=':', alpha=0.4)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(t, sc['obs_v'], label='obs_v')\n",
        "    plt.plot(t, sc['sim_v'], label='sim_v')\n",
        "    plt.xlabel('Frame ID'); plt.ylabel('Speed'); plt.title(f'Vehicle {int(vid)} speed')\n",
        "    plt.legend(); plt.grid(True, linestyle=':', alpha=0.4)\n",
        "    fn = os.path.join(PLOT_DIR, f'eval_vehicle_{int(vid)}_obs_vs_sim.png')\n",
        "    plt.tight_layout(); plt.savefig(fn, dpi=180); plt.close()\n",
        "\n",
        "print(f\"Saved evaluation obs-vs-sim plots for held-out vehicles to {PLOT_DIR}\")\n",
        "\n",
        "# ===============================\n",
        "# End of script\n",
        "# ===============================\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Plots\n",
        "from IPython.display import Image\n",
        "Image(\"Plots/hist_std_residuals.png\")\n",
        "from google.colab import files\n",
        "#files.download(\"Plots/qq_student_t.png\")\n",
        "files.download(\"Plots/hist_std_residuals.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "XPgui1Z6tCx5",
        "outputId": "4725bd51-a90a-41d2-c737-544a25ef64b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval_vehicle_10_obs_vs_sim.png\t   hist_std_residuals.png  res_vehicle_15.png\n",
            "eval_vehicle_12638_obs_vs_sim.png  qq_student_t.png\t   res_vehicle_1939.png\n",
            "eval_vehicle_3054_obs_vs_sim.png   residuals_index.png\t   res_vehicle_26.png\n",
            "eval_vehicle_5167_obs_vs_sim.png   res_vehicle_10.png\t   res_vehicle_9.png\n",
            "eval_vehicle_9683_obs_vs_sim.png   res_vehicle_1342.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_421c34e5-fc8f-4a92-b492-0752dde660b9\", \"hist_std_residuals.png\", 96879)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def compute_normal_mle_aic_bic(residuals):\n",
        "    \"\"\"\n",
        "    Computes log-likelihood, AIC, BIC assuming a Gaussian model with\n",
        "    mean zero and sigma estimated by MLE (population std).\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(residuals)\n",
        "\n",
        "    # MLE sigma uses ddof=0 (population)\n",
        "    sigma_mle = np.std(residuals, ddof=0)\n",
        "\n",
        "    # Compute Gaussian log-likelihood\n",
        "    ll = np.sum(norm.logpdf(residuals, loc=0.0, scale=sigma_mle))\n",
        "\n",
        "    # Number of parameters:\n",
        "    # a, b, and σ  -->  k = 3\n",
        "    k = 3\n",
        "\n",
        "    # AIC & BIC\n",
        "    aic = 2 * k - 2 * ll\n",
        "    bic = k * np.log(n) - 2 * ll\n",
        "\n",
        "    return ll, aic, bic, sigma_mle\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Example usage inside your script:\n",
        "# ---------------------------\n",
        "\n",
        "ll_norm, aic_norm, bic_norm, sigma_norm = compute_normal_mle_aic_bic(residuals_all)\n",
        "\n",
        "print(f\"\\nGaussian MLE σ = {sigma_norm:.6f}\")\n",
        "print(f\"Gaussian log-likelihood = {ll_norm:.4f}\")\n",
        "print(f\"Gaussian AIC = {aic_norm:.4f}\")\n",
        "print(f\"Gaussian BIC = {bic_norm:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzktrU0DwD_N",
        "outputId": "1de317e1-5dab-4760-d661-b9ed75d5c87e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gaussian MLE σ = 0.336451\n",
            "Gaussian log-likelihood = -5770.8060\n",
            "Gaussian AIC = 11547.6120\n",
            "Gaussian BIC = 11570.8809\n",
            "\n"
          ]
        }
      ]
    }
  ]
}